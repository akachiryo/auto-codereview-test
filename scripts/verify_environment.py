#!/usr/bin/env python3
"""
Environment Verification Script v3.0
Checks all environment variables, files, and data integrity before setup
"""

import os
import csv
import time
from typing import Dict, List, Optional

def check_environment_variables():
    """ç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” Checking environment variables...")
    
    required_vars = [
        'TEAM_SETUP_TOKEN',
        'GITHUB_REPOSITORY'
    ]
    
    optional_vars = [
        'BATCH_NUMBER',
        'BATCH_SIZE'
    ]
    
    missing_vars = []
    for var in required_vars:
        value = os.environ.get(var)
        if not value:
            missing_vars.append(var)
            print(f"  âŒ {var}: Not set")
        else:
            masked_value = value[:8] + "..." if len(value) > 8 else "***"
            print(f"  âœ… {var}: {masked_value}")
    
    for var in optional_vars:
        value = os.environ.get(var)
        if value:
            print(f"  âœ… {var}: {value}")
        else:
            print(f"  â„¹ï¸ {var}: Not set (optional)")
    
    if missing_vars:
        print(f"âŒ Missing required environment variables: {', '.join(missing_vars)}")
        return False
    
    print("âœ… All required environment variables are set")
    return True

def check_csv_files():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ“Š Checking CSV files...")
    
    csv_files = {
        'data/imakoko_sns_tables.csv': 'Database table design',
        'data/tasks_for_issues.csv': 'Task issues',
        'data/tests_for_issues.csv': 'Test issues'
    }
    
    all_files_ok = True
    total_records = 0
    
    for file_path, description in csv_files.items():
        print(f"  ğŸ“„ Checking {description}: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"    âŒ File not found")
            all_files_ok = False
            continue
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                row_count = len(rows)
                total_records += row_count
                
                print(f"    âœ… Found {row_count} records")
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
                if rows:
                    headers = list(rows[0].keys())
                    print(f"    ğŸ“‹ Headers: {', '.join(headers[:5])}{'...' if len(headers) > 5 else ''}")
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                    if 'title' in headers:
                        non_empty_titles = sum(1 for row in rows if row.get('title', '').strip())
                        print(f"    ğŸ“ Records with titles: {non_empty_titles}/{row_count}")
                        
                        if non_empty_titles < row_count * 0.8:  # 80%æœªæº€ã®å ´åˆè­¦å‘Š
                            print(f"    âš ï¸ Warning: Many records have empty titles")
                
        except Exception as e:
            print(f"    âŒ Error reading file: {str(e)}")
            all_files_ok = False
    
    print(f"\nğŸ“Š Total records across all CSV files: {total_records}")
    
    if all_files_ok:
        print("âœ… All CSV files are accessible and contain data")
    else:
        print("âŒ Some CSV files have issues")
    
    return all_files_ok

def check_directory_structure():
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ“ Checking directory structure...")
    
    required_dirs = ['scripts', 'data']
    optional_dirs = ['wiki', '.github/workflows']
    
    all_dirs_ok = True
    
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])
            print(f"  âœ… {dir_path}: Exists ({file_count} files)")
        else:
            print(f"  âŒ {dir_path}: Not found")
            all_dirs_ok = False
    
    for dir_path in optional_dirs:
        if os.path.exists(dir_path):
            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])
            print(f"  âœ… {dir_path}: Exists ({file_count} files)")
        else:
            print(f"  â„¹ï¸ {dir_path}: Not found (optional)")
    
    return all_dirs_ok

def check_workflow_files():
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nâš™ï¸ Checking workflow files...")
    
    workflow_dir = '.github/workflows'
    if not os.path.exists(workflow_dir):
        print(f"  âŒ Workflow directory not found: {workflow_dir}")
        return False
    
    workflow_files = [f for f in os.listdir(workflow_dir) if f.endswith('.yml') or f.endswith('.yaml')]
    
    if not workflow_files:
        print(f"  âŒ No workflow files found in {workflow_dir}")
        return False
    
    print(f"  ğŸ“‹ Found {len(workflow_files)} workflow files:")
    for file in sorted(workflow_files):
        file_path = os.path.join(workflow_dir, file)
        file_size = os.path.getsize(file_path)
        print(f"    â€¢ {file} ({file_size} bytes)")
    
    # Check for the main workflow
    main_workflow = 'team-setup.yml'
    if main_workflow in workflow_files:
        print(f"  âœ… Main workflow found: {main_workflow}")
    else:
        print(f"  âš ï¸ Main workflow not found: {main_workflow}")
        print(f"    Available workflows: {', '.join(workflow_files)}")
    
    return True

def estimate_processing_requirements():
    """å‡¦ç†è¦ä»¶ã‚’è¦‹ç©ã‚‚ã‚Š"""
    print("\nğŸ“ˆ Estimating processing requirements...")
    
    try:
        # ã‚¿ã‚¹ã‚¯Issuesæ•°ã‚’ç¢ºèª
        task_count = 0
        if os.path.exists('data/tasks_for_issues.csv'):
            with open('data/tasks_for_issues.csv', 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                task_rows = [row for row in reader if row.get('title', '').strip()]
                task_count = len(task_rows)
        
        # ãƒ†ã‚¹ãƒˆIssuesæ•°ã‚’ç¢ºèª
        test_count = 0
        if os.path.exists('data/tests_for_issues.csv'):
            with open('data/tests_for_issues.csv', 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                test_rows = [row for row in reader if row.get('title', '').strip()]
                test_count = len(test_rows)
        
        total_issues = task_count + test_count
        
        print(f"  ğŸ“ Task issues to create: {task_count}")
        print(f"  ğŸ§ª Test issues to create: {test_count}")
        print(f"  ğŸ“Š Total issues to create: {total_issues}")
        
        # ãƒãƒƒãƒæ•°ã‚’è¨ˆç®—
        batch_size = int(os.environ.get('BATCH_SIZE', '50'))
        required_batches = (total_issues + batch_size - 1) // batch_size  # åˆ‡ã‚Šä¸Šã’
        
        print(f"  ğŸ“¦ Batch size: {batch_size}")
        print(f"  ğŸ”„ Required batches: {required_batches}")
        
        # æ¨å®šå®Ÿè¡Œæ™‚é–“
        estimated_time_per_issue = 3  # ç§’ï¼ˆRate limitè€ƒæ…®ï¼‰
        estimated_total_time = total_issues * estimated_time_per_issue
        estimated_minutes = estimated_total_time // 60
        
        print(f"  â±ï¸ Estimated processing time: {estimated_minutes} minutes ({estimated_total_time} seconds)")
        
        if total_issues > 200:
            print(f"  âš ï¸ Warning: Large number of issues may hit GitHub rate limits")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Error estimating requirements: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ” ENVIRONMENT VERIFICATION v3.0")
    print("=" * 60)
    print(f"â° Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ Working directory: {os.getcwd()}")
    print(f"ğŸ”§ Script: verify_environment.py v3.0")
    print("=" * 60)
    
    # All verification checks
    checks = [
        ("Environment Variables", check_environment_variables),
        ("CSV Files", check_csv_files),
        ("Directory Structure", check_directory_structure),
        ("Workflow Files", check_workflow_files),
        ("Processing Requirements", estimate_processing_requirements)
    ]
    
    all_passed = True
    results = {}
    
    for check_name, check_func in checks:
        try:
            result = check_func()
            results[check_name] = result
            if not result:
                all_passed = False
        except Exception as e:
            print(f"\nâŒ Error during {check_name} check: {str(e)}")
            results[check_name] = False
            all_passed = False
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ VERIFICATION SUMMARY")
    print("=" * 60)
    
    for check_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {status} {check_name}")
    
    if all_passed:
        print("\nğŸ‰ All verification checks passed!")
        print("âœ… Environment is ready for team setup")
        return 0
    else:
        print("\nâš ï¸ Some verification checks failed!")
        print("âŒ Please fix the issues before running team setup")
        return 1

if __name__ == '__main__':
    exit(main())