#!/usr/bin/env python3
"""
GitHub Issues å…¨è‡ªå‹•ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ v4.1 (SMART)
ã™ã¹ã¦ã®Issueã‚’1ã¤ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‹•çš„ã«å‡¦ç†
ä¾å­˜é–¢ä¿‚ï¼šæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ä½¿ç”¨
"""

import os
import requests
import csv
import time
import sys
from typing import Dict, List, Optional, Tuple
# from concurrent.futures import ThreadPoolExecutor, as_completed  # ä¸¦åˆ—å‡¦ç†ç„¡åŠ¹åŒ–
import threading
import math

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
TEAM_SETUP_TOKEN = os.environ.get('TEAM_SETUP_TOKEN')
GITHUB_REPOSITORY = os.environ.get('GITHUB_REPOSITORY')

# å‹•çš„è¨­å®š
PARALLEL_WORKERS = 1     # é †ç•ªä¿æŒã®ãŸã‚ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†
REQUEST_DELAY = 0.5      # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿ã®ãŸã‚ã®ãƒ‡ã‚£ãƒ¬ã‚¤
BATCH_SIZE = 30          # ãƒãƒƒãƒã‚µã‚¤ã‚º
BURST_LIMIT = 10         # ãƒãƒ¼ã‚¹ãƒˆãƒªãƒŸãƒƒãƒˆ
RETRY_DELAY = 2.0        # ãƒªãƒˆãƒ©ã‚¤é–“éš”
MAX_RETRIES = 3          # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

if not TEAM_SETUP_TOKEN or not GITHUB_REPOSITORY:
    raise ValueError("TEAM_SETUP_TOKEN and GITHUB_REPOSITORY environment variables are required")

REPO_OWNER, REPO_NAME = GITHUB_REPOSITORY.split('/')

# GitHub APIè¨­å®š
API_BASE = 'https://api.github.com'
REST_HEADERS = {
    'Authorization': f'token {TEAM_SETUP_TOKEN}',
    'Accept': 'application/vnd.github.v3+json',
    'X-GitHub-Api-Version': '2022-11-28'
}

# GraphQL APIè¨­å®š
GRAPHQL_URL = 'https://api.github.com/graphql'
GRAPHQL_HEADERS = {
    'Authorization': f'Bearer {TEAM_SETUP_TOKEN}',
    'Content-Type': 'application/json'
}

# ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ­ãƒ¼ã‚«ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³
thread_local = threading.local()

def get_session():
    """ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ­ãƒ¼ã‚«ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    if not hasattr(thread_local, "session"):
        thread_local.session = requests.Session()
        thread_local.session.headers.update(REST_HEADERS)
    return thread_local.session

def load_all_csv_data() -> Tuple[List[Dict], List[Dict]]:
    """å…¨ã¦ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š Loading all CSV data...")
    
    # ã‚¿ã‚¹ã‚¯Issues
    task_issues = []
    task_csv_path = 'data/tasks_for_issues.csv'
    if os.path.exists(task_csv_path):
        with open(task_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            task_issues = [row for row in reader if row.get('title', '').strip()]
    
    # ãƒ†ã‚¹ãƒˆIssues
    test_issues = []
    test_csv_path = 'data/tests_for_issues.csv'
    if os.path.exists(test_csv_path):
        with open(test_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            test_issues = [row for row in reader if row.get('title', '').strip()]
    
    print(f"ğŸ“‹ Loaded: {len(task_issues)} task issues, {len(test_issues)} test issues")
    print(f"ğŸ“Š Total: {len(task_issues) + len(test_issues)} issues to create")
    
    # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®æ•°ä»¶ã®difficultyã‚’ç¢ºèª
    if task_issues:
        print(f"ğŸ” Debug: First few task difficulties:")
        for i, task in enumerate(task_issues[:5]):
            print(f"    Task {i+1}: {task.get('title', 'No title')[:50]}... -> difficulty: '{task.get('difficulty', 'None')}'")
        
        # å„é›£æ˜“åº¦ã®æ•°ã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
        difficulties = {}
        for task in task_issues:
            diff = task.get('difficulty', '')
            difficulties[diff] = difficulties.get(diff, 0) + 1
        print(f"ğŸ” Debug: Difficulty distribution: {difficulties}")
    
    return task_issues, test_issues

def calculate_batches(total_count: int, batch_size: int) -> int:
    """å¿…è¦ãªãƒãƒƒãƒæ•°ã‚’è¨ˆç®—"""
    return math.ceil(total_count / batch_size)

def create_single_issue(issue_data: Dict, index: int, total: int, issue_type: str) -> Optional[Dict]:
    """å˜ä¸€ã®Issueã‚’ä½œæˆï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
    session = get_session()
    
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿ã®ãŸã‚ã®ãƒ‡ã‚£ãƒ¬ã‚¤
    if index > 0:
        time.sleep(REQUEST_DELAY)
    
    for attempt in range(MAX_RETRIES):
        try:
            response = session.post(
                f"{API_BASE}/repos/{GITHUB_REPOSITORY}/issues",
                json=issue_data,
                timeout=30
            )
            
            if response.status_code == 201:
                issue = response.json()
                if attempt > 0:
                    print(f"  âœ… {issue_type} ({index + 1}/{total}) [retry {attempt}]: {issue_data['title'][:50]}...")
                else:
                    print(f"  âœ… {issue_type} ({index + 1}/{total}): {issue_data['title'][:50]}...")
                return issue
            
            elif response.status_code == 403:
                print(f"  â³ Rate limit hit ({index + 1}/{total}) [attempt {attempt + 1}]...")
                time.sleep(RETRY_DELAY * (attempt + 1))  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                continue
                
            elif response.status_code >= 500:
                print(f"  ğŸ”„ Server error ({response.status_code}) ({index + 1}/{total}) [attempt {attempt + 1}]...")
                time.sleep(RETRY_DELAY * (attempt + 1))
                continue
            
            else:
                print(f"  âŒ {issue_type} failed ({index + 1}/{total}): {response.status_code} - {response.text[:100]}")
                break
                
        except Exception as e:
            print(f"  âŒ {issue_type} exception ({index + 1}/{total}) [attempt {attempt + 1}]: {str(e)}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY * (attempt + 1))
                continue
    
    return None

def create_issues_batch(issues_data: List[Tuple], batch_num: int, total_batches: int) -> Tuple[List[Dict], List[Tuple]]:
    """1ã¤ã®ãƒãƒƒãƒã§Issueã‚’ä½œæˆï¼ˆå¤±æ•—ã—ãŸã‚‚ã®ã‚’è¿”ã™ï¼‰"""
    created_issues = []
    failed_issues = []
    
    if not issues_data:
        return created_issues, failed_issues
    
    print(f"ğŸš€ Processing batch {batch_num}/{total_batches} ({len(issues_data)} issues)")
    
    # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å®Ÿè¡Œï¼ˆé †ç•ªä¿æŒã®ãŸã‚ï¼‰
    for i, (issue_data, issue_type) in enumerate(issues_data):
        try:
            issue = create_single_issue(issue_data, i, len(issues_data), issue_type)
            if issue:
                created_issues.append(issue)
            else:
                failed_issues.append((issue_data, issue_type))
        except Exception as e:
            print(f"  âŒ Exception: {str(e)}")
            failed_issues.append((issue_data, issue_type))
    
    print(f"ğŸ“Š Batch {batch_num} result: {len(created_issues)}/{len(issues_data)} issues created, {len(failed_issues)} failed")
    return created_issues, failed_issues

def set_project_field_value_by_name(project_id: str, item_id: str, field_name: str, option_name: str) -> bool:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã§è¨­å®š"""
    print(f"    ğŸ”§ Setting field '{field_name}' to '{option_name}'")
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³IDã‚’å–å¾—
    get_field_query = """
    query($projectId: ID!) {
        node(id: $projectId) {
            ... on ProjectV2 {
                fields(first: 20) {
                    nodes {
                        ... on ProjectV2SingleSelectField {
                            id
                            name
                            options {
                                id
                                name
                            }
                        }
                    }
                }
            }
        }
    }
    """
    
    variables = {'projectId': project_id}
    
    try:
        payload = {'query': get_field_query, 'variables': variables}
        response = requests.post(GRAPHQL_URL, json=payload, headers=GRAPHQL_HEADERS, timeout=30)
        
        if response.status_code != 200:
            print(f"    âŒ Failed to get field info: HTTP {response.status_code}")
            return False
            
        data = response.json()
        if 'errors' in data:
            print(f"    âŒ GraphQL errors: {data['errors']}")
            return False
            
        if 'data' not in data or not data['data'] or not data['data']['node']:
            print(f"    âŒ No data returned")
            return False
            
        # å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        field_id = None
        option_id = None
        
        for field in data['data']['node']['fields']['nodes']:
            if field.get('name') == field_name:
                field_id = field['id']
                print(f"    âœ… Found field '{field_name}' with ID: {field_id}")
                print(f"    ğŸ” Available options: {[opt['name'] for opt in field.get('options', [])]}")
                
                for option in field.get('options', []):
                    if option['name'] == option_name:
                        option_id = option['id']
                        print(f"    âœ… Found option '{option_name}' with ID: {option_id}")
                        break
                break
        
        if not field_id:
            print(f"    âŒ Field '{field_name}' not found")
            return False
            
        if not option_id:
            print(f"    âŒ Option '{option_name}' not found in field '{field_name}'")
            return False
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’è¨­å®š
        update_query = """
        mutation($projectId: ID!, $itemId: ID!, $fieldId: ID!, $value: ProjectV2FieldValue!) {
            updateProjectV2ItemFieldValue(input: {
                projectId: $projectId,
                itemId: $itemId,
                fieldId: $fieldId,
                value: $value
            }) {
                projectV2Item { 
                    id 
                }
            }
        }
        """
        
        update_variables = {
            'projectId': project_id,
            'itemId': item_id,
            'fieldId': field_id,
            'value': {
                'singleSelectOptionId': option_id
            }
        }
        
        update_payload = {'query': update_query, 'variables': update_variables}
        update_response = requests.post(GRAPHQL_URL, json=update_payload, headers=GRAPHQL_HEADERS, timeout=30)
        
        if update_response.status_code == 200:
            update_data = update_response.json()
            if 'errors' not in update_data and 'data' in update_data:
                print(f"    âœ… Successfully set field value")
                return True
            else:
                print(f"    âŒ Update failed: {update_data.get('errors', 'Unknown error')}")
        else:
            print(f"    âŒ Update request failed: HTTP {update_response.status_code}")
        
        return False
        
    except Exception as e:
        print(f"    âŒ Exception setting field value: {str(e)}")
        return False

def set_project_field_value(project_id: str, item_id: str, field_id: str, option_name: str) -> bool:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’è¨­å®š"""
    print(f"    ğŸ”§ Attempting to set field value: {option_name}")
    # ã¾ãšãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³IDã‚’å–å¾—
    get_field_query = """
    query($projectId: ID!) {
        node(id: $projectId) {
            ... on ProjectV2 {
                fields(first: 20) {
                    nodes {
                        ... on ProjectV2SingleSelectField {
                            id
                            name
                            options {
                                id
                                name
                            }
                        }
                    }
                }
            }
        }
    }
    """
    
    variables = {'projectId': project_id}
    
    try:
        payload = {'query': get_field_query, 'variables': variables}
        response = requests.post(GRAPHQL_URL, json=payload, headers=GRAPHQL_HEADERS, timeout=30)
        
        if response.status_code != 200:
            return False
            
        data = response.json()
        if 'errors' in data or 'data' not in data:
            return False
            
        # é›£æ˜“åº¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨å¯¾è±¡ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        option_id = None
        difficulty_field_found = False
        
        for field in data['data']['node']['fields']['nodes']:
            if field.get('name') == 'Difficulty':
                difficulty_field_found = True
                print(f"    ğŸ” Found Difficulty field with options: {[opt['name'] for opt in field.get('options', [])]}")
                for option in field.get('options', []):
                    if option['name'] == option_name:
                        option_id = option['id']
                        print(f"    âœ… Found matching option: {option_name} -> {option_id}")
                        break
                break
        
        if not difficulty_field_found:
            print(f"    âŒ Difficulty field not found in project")
            return False
            
        if not option_id:
            print(f"    âŒ Option '{option_name}' not found in Difficulty field")
            return False
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’è¨­å®š
        update_query = """
        mutation($projectId: ID!, $itemId: ID!, $fieldId: ID!, $value: ProjectV2FieldValue!) {
            updateProjectV2ItemFieldValue(input: {
                projectId: $projectId,
                itemId: $itemId,
                fieldId: $fieldId,
                value: $value
            }) {
                projectV2Item { id }
            }
        }
        """
        
        update_variables = {
            'projectId': project_id,
            'itemId': item_id,
            'fieldId': field_id,
            'value': {
                'singleSelectOptionId': option_id
            }
        }
        
        update_payload = {'query': update_query, 'variables': update_variables}
        update_response = requests.post(GRAPHQL_URL, json=update_payload, headers=GRAPHQL_HEADERS, timeout=30)
        
        if update_response.status_code == 200:
            update_data = update_response.json()
            return 'errors' not in update_data and 'data' in update_data
        return False
        
    except Exception as e:
        print(f"    âš ï¸ Field update error: {str(e)}")
        return False

def load_difficulty_field_info() -> Optional[Tuple[str, str, str]]:
    """é›£æ˜“åº¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open('difficulty_field.txt', 'r', encoding='utf-8') as f:
            line = f.read().strip()
            print(f"    ğŸ” Read difficulty_field.txt: {line}")
            if ':' in line:
                parts = line.split(':')
                if len(parts) >= 3:
                    result = parts[0], parts[1], parts[2]  # title, project_id, field_id
                    print(f"    ğŸ” Parsed difficulty info: {result}")
                    return result
        print(f"    âš ï¸ difficulty_field.txt exists but format is invalid")
        return None
    except FileNotFoundError:
        print(f"    âš ï¸ difficulty_field.txt not found")
        return None

def add_issue_to_project_fast(project_id: str, issue: Dict) -> Optional[str]:
    """é«˜é€Ÿã§Issueã‚’Projectã«è¿½åŠ ã—ã€ã‚¢ã‚¤ãƒ†ãƒ IDã‚’è¿”ã™"""
    query = """
    mutation($projectId: ID!, $contentId: ID!) {
        addProjectV2ItemById(input: {projectId: $projectId, contentId: $contentId}) {
            item { id }
        }
    }
    """
    
    variables = {
        'projectId': project_id,
        'contentId': issue['node_id']
    }
    
    payload = {'query': query, 'variables': variables}
    
    try:
        response = requests.post(
            GRAPHQL_URL, 
            json=payload, 
            headers=GRAPHQL_HEADERS,
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            if 'errors' not in data and 'data' in data:
                return data['data']['addProjectV2ItemById']['item']['id']
        return None
    except:
        return None

def link_issues_to_projects(task_issues: List[Dict], test_issues: List[Dict], project_ids: Dict[str, str]):
    """Issueã‚’Projectsã«ãƒªãƒ³ã‚¯"""
    print("\nğŸ”— Linking issues to projects...")
    
    def link_batch(issues: List[Dict], project_id: str, project_name: str, issue_type: str):
        if not issues or not project_id:
            return 0
        
        print(f"  ğŸ“Œ Linking {len(issues)} {issue_type} issues to {project_name}")
        success_count = 0
        
        # é›£æ˜“åº¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
        difficulty_info = load_difficulty_field_info()
        field_set_count = 0
        
        if issue_type == 'task':
            print(f"    ğŸ” Debug: difficulty_info = {difficulty_info}")
            print(f"    ğŸ” Debug: project_name = {project_name}")
            print(f"    ğŸ” Debug: project_id = {project_id}")
        
        for i, issue in enumerate(issues):
            try:
                item_id = add_issue_to_project_fast(project_id, issue)
                if item_id:
                    success_count += 1
                    
                    # ã‚¿ã‚¹ã‚¯ã®å ´åˆã€é›£æ˜“åº¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨­å®š
                    if issue_type == 'task':
                        print(f"    ğŸ” Debug: issue difficulty = {issue.get('difficulty')}")
                        
                        if (difficulty_info and 'ã‚¿ã‚¹ã‚¯' in project_name and issue.get('difficulty')):
                            _, task_project_id, stored_field_id = difficulty_info
                            print(f"    ğŸ” Debug: Attempting to set field. project_id match: {project_id == task_project_id}")
                            
                            if project_id == task_project_id:
                                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰IDã¯ä½¿ã‚ãšã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã§ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«æ¤œç´¢
                                if set_project_field_value_by_name(project_id, item_id, 'Difficulty', issue['difficulty']):
                                    field_set_count += 1
                                    print(f"    âœ… Set difficulty '{issue['difficulty']}' for issue {issue.get('title', 'Unknown')}")
                                else:
                                    print(f"    âŒ Failed to set difficulty for issue {issue.get('title', 'Unknown')}")
                        else:
                            print(f"    âš ï¸ Skipping difficulty set: difficulty_info={bool(difficulty_info)}, has_ã‚¿ã‚¹ã‚¯={'ã‚¿ã‚¹ã‚¯' in project_name}, has_difficulty={bool(issue.get('difficulty'))}")
                
                if (i + 1) % 20 == 0:
                    print(f"    âœ… Linked {i + 1}/{len(issues)} to {project_name}")
            except Exception as e:
                print(f"    âŒ Link exception: {str(e)}")
            time.sleep(0.1)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ³ã‚¯ã‚‚å°‘ã—é–“éš”ã‚’ç©ºã‘ã‚‹
        
        print(f"  ğŸ“Š {project_name}: {success_count}/{len(issues)} issues linked")
        if issue_type == 'task' and field_set_count > 0:
            print(f"  ğŸ·ï¸ {project_name}: {field_set_count}/{success_count} difficulty fields set")
        return success_count
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒªãƒ³ã‚¯
    task_linked = link_batch(
        task_issues, 
        project_ids.get('ã‚¤ãƒã‚³ã‚³SNSï¼ˆã‚¿ã‚¹ã‚¯ï¼‰'), 
        'ã‚¤ãƒã‚³ã‚³SNSï¼ˆã‚¿ã‚¹ã‚¯ï¼‰',
        'task'
    )
    
    test_linked = link_batch(
        test_issues,
        project_ids.get('ã‚¤ãƒã‚³ã‚³SNSï¼ˆãƒ†ã‚¹ãƒˆï¼‰'),
        'ã‚¤ãƒã‚³ã‚³SNSï¼ˆãƒ†ã‚¹ãƒˆï¼‰',
        'test'
    )
    
    return task_linked, test_linked

def load_project_ids() -> Dict[str, str]:
    """ä¿å­˜ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’èª­ã¿è¾¼ã¿"""
    project_ids = {}
    try:
        with open('project_ids.txt', 'r', encoding='utf-8') as f:
            for line in f:
                if ':' in line:
                    title, project_id = line.strip().split(':', 1)
                    project_ids[title] = project_id
        print(f"ğŸ“‚ Loaded {len(project_ids)} project IDs")
    except FileNotFoundError:
        print("âš ï¸ project_ids.txt not found. Issues will be created but not linked to projects.")
    
    return project_ids

def prepare_issue_data(issues: List[Dict], labels: List[str]) -> List[Tuple[Dict, str]]:
    """Issueä½œæˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆç•ªå·ä»˜ãã‚¿ã‚¤ãƒˆãƒ«ï¼‰"""
    issue_requests = []
    issue_type = 'task' if 'task' in labels else 'test'
    
    for index, row in enumerate(issues, 1):
        title = row.get('title', '').strip()
        body = row.get('body', '').strip()
        
        if not title:
            continue
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã«ç•ªå·ã‚’è¿½åŠ ï¼ˆæ—¢ã«ç•ªå·ãŒã‚ã‚‹å ´åˆã¯ç½®ãæ›ãˆï¼‰
        if issue_type == 'task':
            # ã€Œã‚¿ã‚¹ã‚¯ã€ã§å§‹ã¾ã‚‹å ´åˆã¯ã€ç•ªå·ã‚’ç½®ãæ›ãˆ
            if title.startswith('ã‚¿ã‚¹ã‚¯'):
                # ã€Œã‚¿ã‚¹ã‚¯ã€ã®å¾Œã®æ•°å­—ã‚„ã‚³ãƒ­ãƒ³ã‚’å‰Šé™¤ã—ã€æœ¬æ–‡ã‚’æŠ½å‡º
                import re
                match = re.match(r'ã‚¿ã‚¹ã‚¯[\d\s:.]*(.+)', title)
                if match:
                    clean_title = match.group(1).strip()
                else:
                    clean_title = title
                numbered_title = f"ã‚¿ã‚¹ã‚¯{index:03d}: {clean_title}"
            else:
                numbered_title = f"ã‚¿ã‚¹ã‚¯{index:03d}: {title}"
        else:
            # ã€Œãƒ†ã‚¹ãƒˆã€ã§å§‹ã¾ã‚‹å ´åˆã¯ã€ç•ªå·ã‚’ç½®ãæ›ãˆ
            if title.startswith('ãƒ†ã‚¹ãƒˆ'):
                import re
                match = re.match(r'ãƒ†ã‚¹ãƒˆ[\d\s:.]*(.+)', title)
                if match:
                    clean_title = match.group(1).strip()
                else:
                    clean_title = title
                numbered_title = f"ãƒ†ã‚¹ãƒˆ{index:03d}: {clean_title}"
            else:
                numbered_title = f"ãƒ†ã‚¹ãƒˆ{index:03d}: {title}"
            
        existing_labels = [label.strip() for label in row.get('labels', '').split(',') if label.strip()]
        all_labels = list(set(existing_labels + labels))
        
        # é›£æ˜“åº¦æƒ…å ±ã‚’å–å¾—ï¼ˆã‚¿ã‚¹ã‚¯ã®ã¿ï¼‰
        difficulty = row.get('difficulty', '').strip() if issue_type == 'task' else None
        
        issue_data = {
            'title': numbered_title,
            'body': body,
            'labels': all_labels,
            'difficulty': difficulty
        }
        
        issue_requests.append((issue_data, issue_type))
    
    return issue_requests

def retry_failed_issues(failed_issues: List[Tuple], max_retry_rounds: int = 2) -> List[Dict]:
    """å¤±æ•—ã—ãŸissueã‚’ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹"""
    if not failed_issues:
        return []
    
    print(f"\nğŸ”„ Retrying {len(failed_issues)} failed issues...")
    
    retry_created = []
    remaining_failed = failed_issues.copy()
    
    for round_num in range(max_retry_rounds):
        if not remaining_failed:
            break
            
        print(f"  ğŸ” Retry round {round_num + 1}/{max_retry_rounds}: {len(remaining_failed)} issues")
        
        # ãƒªãƒˆãƒ©ã‚¤å‰ã«é•·ã‚ã®ä¼‘æ†©
        time.sleep(3.0)
        
        current_round_created, current_round_failed = create_issues_batch(
            remaining_failed, round_num + 1, max_retry_rounds
        )
        
        retry_created.extend(current_round_created)
        remaining_failed = current_round_failed
        
        # æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã¾ã§ã®ä¼‘æ†©
        if remaining_failed and round_num < max_retry_rounds - 1:
            print(f"    â³ Waiting before next retry round...")
            time.sleep(5.0)
    
    if remaining_failed:
        print(f"  âš ï¸ {len(remaining_failed)} issues could not be created after all retries")
        print("  Failed issues:")
        for issue_data, issue_type in remaining_failed[:5]:  # æœ€åˆã®5å€‹ã ã‘è¡¨ç¤º
            print(f"    - {issue_type}: {issue_data['title'][:50]}...")
        if len(remaining_failed) > 5:
            print(f"    ... and {len(remaining_failed) - 5} more")
    
    print(f"  âœ… Retry success: {len(retry_created)} issues created")
    return retry_created

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ§  SMART ALL-IN-ONE ISSUE CREATOR v4.3 (sequential + numbered)")
    print("=" * 60)
    print(f"ğŸ“¦ Repository: {GITHUB_REPOSITORY}")
    print(f"â° Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ Script: create_all_issues_smart.py v4.3")
    print(f"âš™ï¸ Configuration:")
    print(f"  â€¢ Parallel Workers: {PARALLEL_WORKERS}")
    print(f"  â€¢ Request Delay: {REQUEST_DELAY}s")
    print(f"  â€¢ Retry Delay: {RETRY_DELAY}s")
    print(f"  â€¢ Max Retries: {MAX_RETRIES}")
    print(f"  â€¢ Batch Size: {BATCH_SIZE}")
    print(f"  â€¢ Dependencies: Standard library only")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        task_data, test_data = load_all_csv_data()
        total_issues = len(task_data) + len(test_data)
        
        if total_issues == 0:
            print("âš ï¸ No issues found in CSV files")
            return 1
        
        # ãƒãƒƒãƒè¨ˆç®—
        total_batches = calculate_batches(total_issues, BATCH_SIZE)
        print(f"\nğŸ“Š Processing plan:")
        print(f"  â€¢ Total issues: {total_issues}")
        print(f"  â€¢ Batch size: {BATCH_SIZE}")
        print(f"  â€¢ Total batches: {total_batches}")
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’èª­ã¿è¾¼ã¿
        project_ids = load_project_ids()
        
        # Issueä½œæˆç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
        task_requests = prepare_issue_data(task_data, ['task', 'development'])
        test_requests = prepare_issue_data(test_data, ['test', 'qa'])
        all_requests = task_requests + test_requests
        
        print(f"\nğŸ“‹ Prepared requests: {len(all_requests)} issues")
        
        # ãƒãƒƒãƒå‡¦ç†
        all_created_issues = []
        task_created = []
        test_created = []
        
        for batch_num in range(total_batches):
            start_idx = batch_num * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, len(all_requests))
            batch_requests = all_requests[start_idx:end_idx]
            
            print(f"\nğŸ”„ Batch {batch_num + 1}/{total_batches}: Processing issues {start_idx + 1}-{end_idx}")
            
            batch_created, batch_failed = create_issues_batch(batch_requests, batch_num + 1, total_batches)
            all_created_issues.extend(batch_created)
            
            # å¤±æ•—ã—ãŸã‚‚ã®ã‚’é›†ç´„
            if batch_failed:
                print(f"  ğŸ“ {len(batch_failed)} issues failed in this batch, will retry later...")
                if 'all_failed_issues' not in locals():
                    all_failed_issues = []
                all_failed_issues.extend(batch_failed)
            
            # ã‚¿ã‚¹ã‚¯/ãƒ†ã‚¹ãƒˆåˆ¥ã«åˆ†é¡
            for issue in batch_created:
                issue_labels = [label['name'] for label in issue.get('labels', [])]
                if 'task' in issue_labels:
                    task_created.append(issue)
                else:
                    test_created.append(issue)
            
            # ãƒãƒƒãƒé–“ã®ä¼‘æ†©
            if batch_num < total_batches - 1:
                print(f"  â³ Batch pause...")
                time.sleep(2)
        
        # å¤±æ•—ã—ãŸã‚‚ã®ã®ãƒªãƒˆãƒ©ã‚¤
        retry_created = []
        if 'all_failed_issues' in locals() and all_failed_issues:
            retry_created = retry_failed_issues(all_failed_issues)
            all_created_issues.extend(retry_created)
            
            # ãƒªãƒˆãƒ©ã‚¤ã§ä½œæˆã•ã‚ŒãŸã‚‚ã®ã‚‚åˆ†é¡
            for issue in retry_created:
                issue_labels = [label['name'] for label in issue.get('labels', [])]
                if 'task' in issue_labels:
                    task_created.append(issue)
                else:
                    test_created.append(issue)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ³ã‚¯
        task_linked, test_linked = link_issues_to_projects(task_created, test_created, project_ids)
        
        # çµæœã‚µãƒãƒªãƒ¼
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"\n" + "=" * 60)
        print("ğŸ‰ SMART PROCESSING COMPLETED!")
        print("=" * 60)
        print(f"ğŸ“Š Results:")
        print(f"  â€¢ Task issues created: {len(task_created)}")
        print(f"  â€¢ Test issues created: {len(test_created)}")
        print(f"  â€¢ Total issues created: {len(all_created_issues)}")
        if retry_created:
            print(f"  â€¢ Retry issues created: {len(retry_created)}")
        print(f"  â€¢ Task issues linked: {task_linked}")
        print(f"  â€¢ Test issues linked: {test_linked}")
        final_failed = len(all_failed_issues) - len(retry_created) if 'all_failed_issues' in locals() else 0
        if final_failed > 0:
            print(f"  â€¢ Final failed issues: {final_failed}")
        print(f"  â€¢ Success rate: {(len(all_created_issues)/total_issues*100):.1f}%")
        print(f"â±ï¸ Performance:")
        print(f"  â€¢ Execution time: {execution_time:.1f} seconds")
        print(f"  â€¢ Average per issue: {(execution_time/len(all_created_issues)):.2f}s")
        
        # çµæœä¿å­˜
        with open('smart_issue_creation_result.txt', 'w', encoding='utf-8') as f:
            f.write(f"Smart Issue Creation Results\n")
            f.write(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Task issues: {len(task_created)}\n")
            f.write(f"Test issues: {len(test_created)}\n")
            f.write(f"Total: {len(all_created_issues)}\n")
            if retry_created:
                f.write(f"Retry issues: {len(retry_created)}\n")
            final_failed = len(all_failed_issues) - len(retry_created) if 'all_failed_issues' in locals() else 0
            if final_failed > 0:
                f.write(f"Final failed issues: {final_failed}\n")
            f.write(f"Execution time: {execution_time:.1f}s\n")
            f.write(f"Success rate: {(len(all_created_issues)/total_issues*100):.1f}%\n")
        
        return 0
        
    except Exception as e:
        print(f"\nğŸ’¥ Unexpected error: {str(e)}")
        print(f"ğŸ”§ Error type: {type(e).__name__}")
        return 1

if __name__ == '__main__':
    exit(main())