#!/usr/bin/env python3
"""
ã‚¿ã‚¹ã‚¯Issueä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¸¦åˆ—å®Ÿè¡Œæœ€é©åŒ–ç‰ˆï¼‰
"""

import os
import requests
import csv
import time
import math
import random
from typing import Dict, List, Optional

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
TEAM_SETUP_TOKEN = os.environ.get('TEAM_SETUP_TOKEN')
GITHUB_REPOSITORY = os.environ.get('GITHUB_REPOSITORY')

# Rate Limitè¨­å®šï¼ˆä¿å®ˆçš„ï¼‰
REQUEST_DELAY = 1.5      # 1.5ç§’é–“éš”ï¼ˆRateåˆ¶é™å›é¿ï¼‰
BATCH_SIZE = 10          # å°ã•ã‚ã®ãƒãƒƒãƒ
BATCH_PAUSE = 15.0       # é•·ã‚ã®ä¼‘æ†©
MAX_RETRIES = 5          # ãƒªãƒˆãƒ©ã‚¤å›æ•°å‰Šæ¸›

if not TEAM_SETUP_TOKEN or not GITHUB_REPOSITORY:
    raise ValueError("TEAM_SETUP_TOKEN and GITHUB_REPOSITORY environment variables are required")

# GitHub APIè¨­å®š
API_BASE = 'https://api.github.com'
HEADERS = {
    'Authorization': f'token {TEAM_SETUP_TOKEN}',
    'Accept': 'application/vnd.github.v3+json',
    'X-GitHub-Api-Version': '2022-11-28'
}

def load_task_data() -> List[Dict]:
    """ã‚¿ã‚¹ã‚¯CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š Loading task data...")
    
    task_issues = []
    csv_path = 'data/tasks_for_issues.csv'
    
    if os.path.exists(csv_path):
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            task_issues = [row for row in reader if row.get('title', '').strip()]
    
    print(f"ğŸ“‹ Loaded: {len(task_issues)} task issues")
    return task_issues

def create_single_issue(issue_data: Dict, index: int, total: int) -> Optional[Dict]:
    """å˜ä¸€ã®ã‚¿ã‚¹ã‚¯Issueã‚’ä½œæˆ"""
    session = requests.Session()
    session.headers.update(HEADERS)
    
    if index > 0:
        time.sleep(REQUEST_DELAY)
    
    for attempt in range(MAX_RETRIES):
        try:
            response = session.post(
                f"{API_BASE}/repos/{GITHUB_REPOSITORY}/issues",
                json=issue_data,
                timeout=30
            )
            
            if response.status_code == 201:
                issue = response.json()
                print(f"  âœ… Task ({index + 1}/{total}): {issue_data['title'][:50]}...")
                return issue
            
            elif response.status_code == 403:
                retry_after = response.headers.get('retry-after')
                if retry_after:
                    wait_time = int(retry_after) + 10  # ä½™è£•ã‚’æŒãŸã›ã‚‹
                else:
                    wait_time = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60ç§’å¾…æ©Ÿ
                remaining = response.headers.get('x-ratelimit-remaining', 'unknown')
                print(f"  â³ Rate limit hit (remaining: {remaining}), waiting {wait_time}s...")
                time.sleep(wait_time)
                continue
                
            else:
                print(f"  âŒ Task failed ({index + 1}/{total}): {response.status_code}")
                break
                
        except Exception as e:
            print(f"  âŒ Exception ({index + 1}/{total}): {str(e)}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(30 * (attempt + 1))
                continue
    
    return None

def prepare_task_data(tasks: List[Dict]) -> List[Dict]:
    """ã‚¿ã‚¹ã‚¯Issueä½œæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
    task_requests = []
    
    for index, row in enumerate(tasks, 1):
        title = row.get('title', '').strip()
        body = row.get('body', '').strip()
        
        if not title:
            continue
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç•ªå·ã®æ•´ç†
        if title.startswith('ã‚¿ã‚¹ã‚¯'):
            import re
            match = re.match(r'ã‚¿ã‚¹ã‚¯[\d\s:.]*(.+)', title)
            if match:
                clean_title = match.group(1).strip()
            else:
                clean_title = title
            numbered_title = f"ã‚¿ã‚¹ã‚¯{index:03d}: {clean_title}"
        else:
            numbered_title = f"ã‚¿ã‚¹ã‚¯{index:03d}: {title}"
        
        # ãƒ©ãƒ™ãƒ«å‡¦ç†
        labels_str = row.get('labels', '').strip()
        if labels_str.startswith('"') and labels_str.endswith('"'):
            labels_str = labels_str[1:-1]
        labels = [label.strip() for label in labels_str.split(',') if label.strip()]
        
        if 'task' not in labels:
            labels.append('task')
        
        issue_data = {
            'title': numbered_title,
            'body': body,
            'labels': labels
        }
        
        task_requests.append(issue_data)
    
    return task_requests

def create_task_issues_batch(issues_data: List[Dict], batch_num: int, total_batches: int, start_time: float) -> List[Dict]:
    """ã‚¿ã‚¹ã‚¯Issuesã‚’ãƒãƒƒãƒä½œæˆ"""
    created_issues = []
    
    print(f"ğŸš€ Processing task batch {batch_num}/{total_batches} ({len(issues_data)} issues)")
    
    for i, issue_data in enumerate(issues_data):
        issue = create_single_issue(issue_data, i, len(issues_data))
        if issue:
            created_issues.append(issue)
        
        # é€²æ—è¡¨ç¤ºï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆé˜²æ­¢ï¼‰
        if (i + 1) % 5 == 0:
            elapsed = time.time() - start_time
            print(f"  ğŸ“Š Progress: {i + 1}/{len(issues_data)} in batch {batch_num} - Elapsed: {elapsed:.1f}s")
    
    print(f"ğŸ“Š Task batch {batch_num} result: {len(created_issues)}/{len(issues_data)} issues created")
    return created_issues

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ“‹ TASK ISSUE CREATOR (Parallel Optimized)")
    print("=" * 60)
    print(f"ğŸ“¦ Repository: {GITHUB_REPOSITORY}")
    print(f"âš™ï¸ Settings: delay={REQUEST_DELAY}s, batch_size={BATCH_SIZE}")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯
        if os.path.exists('project_status.txt'):
            with open('project_status.txt', 'r') as f:
                status = f.read().strip()
            if status == 'ALL_SKIPPED':
                print("\nâœ… All projects already exist. Skipping task issue creation.")
                print("ğŸ’¡ Projects were reused from previous setup.")
                # ç©ºã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆå¾Œç¶šå‡¦ç†ã®ãŸã‚ï¼‰
                with open('task_issues_result.txt', 'w', encoding='utf-8') as f:
                    f.write("Task Issues: SKIPPED (projects already exist)\n")
                return 0
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        task_data = load_task_data()
        
        if not task_data:
            print("âš ï¸ No task issues found")
            return 0
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        task_requests = prepare_task_data(task_data)
        total_batches = math.ceil(len(task_requests) / BATCH_SIZE)
        
        print(f"ğŸ“‹ Processing {len(task_requests)} task issues in {total_batches} batches")
        
        # ãƒãƒƒãƒå‡¦ç†
        all_created = []
        
        for batch_num in range(total_batches):
            start_idx = batch_num * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, len(task_requests))
            batch_requests = task_requests[start_idx:end_idx]
            
            batch_created = create_task_issues_batch(batch_requests, batch_num + 1, total_batches, start_time)
            all_created.extend(batch_created)
            
            # ãƒãƒƒãƒé–“ä¼‘æ†©
            if batch_num < total_batches - 1:
                print(f"  â³ Batch pause ({BATCH_PAUSE}s)...")
                time.sleep(BATCH_PAUSE)
        
        # çµæœä¿å­˜
        with open('task_issues_result.txt', 'w', encoding='utf-8') as f:
            f.write(f"Task Issues Created: {len(all_created)}\n")
            f.write(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Execution time: {time.time() - start_time:.1f}s\n")
            
            for issue in all_created:
                f.write(f"{issue['number']}: {issue['title']}\n")
        
        print(f"\nâœ… Task issues completed: {len(all_created)}/{len(task_requests)}")
        print(f"â±ï¸ Execution time: {time.time() - start_time:.1f}s")
        
        return 0
        
    except Exception as e:
        print(f"ğŸ’¥ Error: {str(e)}")
        return 1

if __name__ == '__main__':
    exit(main())